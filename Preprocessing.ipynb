{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBLuNyhQM2r4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CxA6yE7NydC"
      },
      "outputs": [],
      "source": [
        "def load_dataset(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = []\n",
        "\n",
        "    # Read directory and get class list\n",
        "    df = sorted(os.listdir(directory))\n",
        "\n",
        "    # Iterate through each class\n",
        "    for i, nama_kelas in enumerate(df):\n",
        "        class_dir = os.path.join(directory, nama_kelas)\n",
        "\n",
        "        # Read each image in the class\n",
        "        for file_name in os.listdir(class_dir):\n",
        "            if file_name.lower().endswith('.jpg'):\n",
        "                image_path = os.path.join(class_dir, file_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(i)\n",
        "\n",
        "        # Store class name\n",
        "        class_names.append(nama_kelas)\n",
        "\n",
        "    return np.array(images, dtype=object), np.array(labels), class_names\n",
        "\n",
        "def count_samples_per_class(labels, class_names):\n",
        "    sample_counts = []\n",
        "    for nama_kelas in class_names:\n",
        "        count = np.sum(labels == class_names.index(nama_kelas))\n",
        "        sample_counts.append(count)\n",
        "    return sample_counts\n",
        "\n",
        "def rotate_image(image, angle):\n",
        "\n",
        "    # Rotate the image by the specified angle.\n",
        "    if angle == 90:\n",
        "        return np.rot90(image)\n",
        "    else:\n",
        "        raise ValueError(\"Only 90 degree rotation is supported.\")\n",
        "\n",
        "def image_exists(image, images):\n",
        "\n",
        "    # Check if the image already exists in the dataset.\n",
        "    for img in images:\n",
        "        if np.array_equal(image, img):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def random_oversampling(images, labels, minority_class, oversampling_ratio):\n",
        "    # Determine the indices of samples from the minority class\n",
        "    minority_indices = np.where(labels == minority_class)[0]\n",
        "    minority_count = len(minority_indices)\n",
        "    target_count = int(oversampling_ratio * minority_count)\n",
        "\n",
        "    oversampled_images = []\n",
        "    oversampled_labels = []\n",
        "\n",
        "    while len(oversampled_images) < target_count:\n",
        "        random_index = np.random.choice(minority_indices)\n",
        "        random_image = images[random_index]\n",
        "\n",
        "        # Rotate the image by 90 degrees\n",
        "        rotated_image = rotate_image(random_image, 90)\n",
        "\n",
        "        if not image_exists(rotated_image, images):\n",
        "            oversampled_images.append(rotated_image)\n",
        "            oversampled_labels.append(minority_class)\n",
        "\n",
        "    # Combine the original dataset with the oversampled results\n",
        "    images = np.concatenate((images, oversampled_images), axis=0)\n",
        "    labels = np.concatenate((labels, oversampled_labels), axis=0)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    images, labels = shuffle(images, labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Path to the directory containing the images\n",
        "directory = '/content/drive/MyDrive/Capstone/data mentah'\n",
        "images, labels, class_names = load_dataset(directory)\n",
        "\n",
        "# Display dataset information\n",
        "print(\"Number of classes:\", len(class_names))\n",
        "print(\"Total number of images:\", len(images))\n",
        "\n",
        "# Apply random oversampling to the minority class\n",
        "minority_class = 'Gray_Leaf_Spot'\n",
        "minority_class_index = class_names.index(minority_class)\n",
        "oversampled_images, oversampled_labels = random_oversampling(images, labels, minority_class_index, oversampling_ratio=1.0)\n",
        "\n",
        "# Display information after oversampling\n",
        "print(\"Total number of images after oversampling:\", len(oversampled_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Gg8D7jCLPQW1",
        "outputId": "f8633b45-a807-4bda-aae2-7dd94b3e5d22"
      },
      "outputs": [],
      "source": [
        "# Count samples per class before and after oversampling\n",
        "original_sample_counts = count_samples_per_class(labels, class_names)\n",
        "oversampled_sample_counts = count_samples_per_class(oversampled_labels, class_names)\n",
        "\n",
        "print(\"\\nNumber of samples per class before oversampling:\")\n",
        "for i, nama_kelas in enumerate(class_names):\n",
        "    print(f\"{nama_kelas}: {original_sample_counts[i]}\")\n",
        "\n",
        "print(\"\\nNumber of samples per class after oversampling:\")\n",
        "for i, nama_kelas in enumerate(class_names):\n",
        "    print(f\"{nama_kelas}: {oversampled_sample_counts[i]}\")\n",
        "\n",
        "# Save the oversampled data to the output directory\n",
        "output_dir = '/content/drive/MyDrive/Capstone/data_oversampling'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for i in range(len(oversampled_images)):\n",
        "    nama_kelas = class_names[oversampled_labels[i]]\n",
        "    image_name = f\"{nama_kelas}_{i}.jpg\"\n",
        "    image_path = os.path.join(output_dir, nama_kelas, image_name)\n",
        "\n",
        "    os.makedirs(os.path.dirname(image_path), exist_ok=True)\n",
        "    cv2.imwrite(image_path, cv2.cvtColor(oversampled_images[i], cv2.COLOR_RGB2BGR))\n",
        "\n",
        "print(\"\\nOversampled data has been saved to the directory:\", output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpmTq56tQ7t8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def compute_image_hash(image_path):\n",
        "\n",
        "    #Compute the hash of an image\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize((256, 256)).convert('L')\n",
        "        return hashlib.md5(img.tobytes()).hexdigest()\n",
        "\n",
        "def find_duplicates(directory):\n",
        "\n",
        "    #Find and print duplicates in the given directory.\n",
        "    file_hashes = {}\n",
        "    duplicates = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.jpg'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                file_hash = compute_image_hash(file_path)\n",
        "\n",
        "                if file_hash in file_hashes:\n",
        "                    duplicates.append((file_path, file_hashes[file_hash]))\n",
        "                    print(f\"Duplicate found: {file_path} is a duplicate of {file_hashes[file_hash]}\")\n",
        "                else:\n",
        "                    file_hashes[file_hash] = file_path\n",
        "\n",
        "    if not duplicates:\n",
        "        print(\"No duplicates found.\")\n",
        "    else:\n",
        "        print(f\"Total {len(duplicates)} duplicates found.\")\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "# Path to the directory containing the images\n",
        "directory = \"/content/drive/MyDrive/Capstone/data_oversampling\"\n",
        "duplicates = find_duplicates(directory)\n",
        "\n",
        "# Optionally save the list of duplicates to a file\n",
        "with open(\"duplicates.txt\", \"w\") as f:\n",
        "    for duplicate in duplicates:\n",
        "        f.write(f\"{duplicate[0]} is a duplicate of {duplicate[1]}\\n\")\n",
        "    print(\"List of duplicates has been saved to 'duplicates.txt'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojyAEZ9zRE07"
      },
      "outputs": [],
      "source": [
        "def remove_duplicates(duplicates):\n",
        "\n",
        "    #Remove duplicate files.\n",
        "    for duplicate in duplicates:\n",
        "        duplicate_file = duplicate[0]\n",
        "        try:\n",
        "            os.remove(duplicate_file)\n",
        "            print(f\"Removed duplicate file: {duplicate_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error removing file {duplicate_file}: {e}\")\n",
        "\n",
        "remove_duplicates(duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyCwKzyLRfER"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path within Google Drive\n",
        "directory_path = '/content/drive/MyDrive/Capstone/data_oversampling/Blight'\n",
        "\n",
        "# Count files\n",
        "file_count = len([name for name in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, name))])\n",
        "\n",
        "print(f'Total number of files in \"{directory_path}\": {file_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaN6pmj_R6Up"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path within Google Drive\n",
        "directory_path = '/content/drive/MyDrive/Capstone/data_oversampling/Common_Rust'\n",
        "\n",
        "# Count files\n",
        "file_count = len([name for name in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, name))])\n",
        "\n",
        "print(f'Total number of files in \"{directory_path}\": {file_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh1E0dchR9PJ"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path within Google Drive\n",
        "directory_path = '/content/drive/MyDrive/Capstone/data_oversampling/Gray_Leaf_Spot'\n",
        "\n",
        "# Count files\n",
        "file_count = len([name for name in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, name))])\n",
        "\n",
        "print(f'Total number of files in \"{directory_path}\": {file_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1wP7N8ESCO0"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path within Google Drive\n",
        "directory_path = '/content/drive/MyDrive/Capstone/data_oversampling/Healthy'\n",
        "\n",
        "# Count files\n",
        "file_count = len([name for name in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, name))])\n",
        "\n",
        "print(f'Total number of files in \"{directory_path}\": {file_count}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
